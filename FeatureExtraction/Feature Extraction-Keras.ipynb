{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Keras with TensorFlow backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Flatten, Dense, Input, Activation\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.preprocessing import image\n",
    "from keras.utils.layer_utils import convert_all_kernels_in_model\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set GPU\n",
    "tf.device('/gpu:0') tells TF to use gpu 0. Can use gpu 1. If cell is not run then fills both GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<contextlib.GeneratorContextManager at 0x66df3d0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.device('/gpu:0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grab Test Image file paths and put into List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2100\n"
     ]
    }
   ],
   "source": [
    "#Grab image paths put in list\n",
    "path = 'UCMerced/Images/'\n",
    "img_paths = []\n",
    "label = []\n",
    "for i in sorted(os.listdir(path)):\n",
    "    for j in sorted(os.listdir(path+i)):\n",
    "        img_paths.append(path + i + '/'+ j)\n",
    "        label.append(j)\n",
    "print len(img_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    }
   ],
   "source": [
    "new_path = 'Cifar/Val/'\n",
    "#Grab image paths put in list\n",
    "img_paths = []\n",
    "for i in sorted(os.listdir(new_path)):\n",
    "    small_path = new_path+i+'/'\n",
    "    for j in sorted(os.listdir(small_path)):\n",
    "        img_paths.append(small_path + j)\n",
    "print len(img_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Functional Keras model from keras.applications Library "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from keras.applications.resnet50 import ResNet50\n",
    "from keras.applications.vgg16 import VGG16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Instance of base model \n",
    "include_top = False gets rid of top model.\n",
    "\n",
    "weights = 'imagenet' Sets weights to image net weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#weights_path = 'Caffe models/ResNet50/weights/ResNet50-finetune4-59-0.83.h5'\n",
    "#model = ResNet50(include_top=False, weights='imagenet', input_tensor=Input(shape=(224,224,3)))\n",
    "\n",
    "model = VGG16(include_top=False, weights='imagenet', input_tensor=Input(shape=(224,224,3)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Top Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ResNet Top Model\n",
    "x = model.output\n",
    "x = Flatten(name='flatten')(x) \n",
    "x = BatchNormalization(axis=1, name='batch_norm')(x)\n",
    "\n",
    "# 344 is the number of classes\n",
    "x = Dense(344, name='fc1000')(x)\n",
    "x = Activation(\"softmax\",name='bfc1000')(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a New Model Class where input is base model and output is Top model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Stack top_model on top\n",
    "final_model = Model(input=model.input, output=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#File handle to open weights path if need to replace Image Net weights\n",
    "weights_path = 'Caffe models/VGG/VGG16-finetune2-24-0.68.h5'\n",
    "f = h5py.File(weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#K.get_session().run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For each layer set the weights from the .h5 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "Model loaded.\n"
     ]
    }
   ],
   "source": [
    "for k in range(len(f.attrs['layer_names'])): \n",
    "    name = f.attrs['layer_names'][k]\n",
    "    weights = [f[name][h][()] for h in f[name].keys()]\n",
    "    print k\n",
    "    final_model.layers[k].set_weights(weights)\n",
    "f.close()\n",
    "print('Model loaded.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a new model to feature extract and any desired layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "layer_name = 'fc1000'\n",
    "intermediate_layer_model = Model(input=final_model.input,\n",
    "                                 output=final_model.get_layer(layer_name).output)\n",
    "#intermediate_layer_model = Model(input=model.input,\n",
    "#                                 output=model.get_layer('avg_pool').output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing Feature Extraction by subtracting by ImageNet mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_input(x):\n",
    "    x[:, :, :, 0] -= 103.939\n",
    "    x[:, :, :, 1] -= 116.779\n",
    "    x[:, :, :, 2] -= 123.68\n",
    "    # 'RGB'->'BGR'\n",
    "    x = x[:, :, :, ::-1]\n",
    "    x = x*(1./255)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Test for 1 image \n",
    "img = image.load_img(img_paths[0], target_size=(224, 224))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)\n",
    "test = intermediate_layer_model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Get all features\n",
    "features = []\n",
    "for i in range(len(img_paths)):\n",
    "    img = image.load_img(img_paths[i], target_size=(224, 224))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    features.append(intermediate_layer_model.predict(x).flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image_features = np.squeeze(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2100, 344)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process to Save extracted Features into Dataframe then to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(np.array(label))\n",
    "df2 = pd.DataFrame(image_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "frames = [df1, df2]\n",
    "result = pd.concat(frames,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>334</th>\n",
       "      <th>335</th>\n",
       "      <th>336</th>\n",
       "      <th>337</th>\n",
       "      <th>338</th>\n",
       "      <th>339</th>\n",
       "      <th>340</th>\n",
       "      <th>341</th>\n",
       "      <th>342</th>\n",
       "      <th>343</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>agricultural00.tif</td>\n",
       "      <td>-17.498186</td>\n",
       "      <td>-11.243931</td>\n",
       "      <td>-2.828087</td>\n",
       "      <td>-5.019659</td>\n",
       "      <td>-4.800480</td>\n",
       "      <td>-0.314717</td>\n",
       "      <td>-1.240391</td>\n",
       "      <td>-10.934299</td>\n",
       "      <td>-13.917276</td>\n",
       "      <td>...</td>\n",
       "      <td>-19.817291</td>\n",
       "      <td>-5.006012</td>\n",
       "      <td>-12.085507</td>\n",
       "      <td>-0.838910</td>\n",
       "      <td>2.503154</td>\n",
       "      <td>-4.625121</td>\n",
       "      <td>-10.408319</td>\n",
       "      <td>-8.315767</td>\n",
       "      <td>-5.782712</td>\n",
       "      <td>-9.969353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>agricultural01.tif</td>\n",
       "      <td>-17.414495</td>\n",
       "      <td>-10.923462</td>\n",
       "      <td>-2.705335</td>\n",
       "      <td>-4.852305</td>\n",
       "      <td>-4.538103</td>\n",
       "      <td>-0.125256</td>\n",
       "      <td>-1.075972</td>\n",
       "      <td>-10.810599</td>\n",
       "      <td>-13.663400</td>\n",
       "      <td>...</td>\n",
       "      <td>-19.632097</td>\n",
       "      <td>-4.853601</td>\n",
       "      <td>-11.882241</td>\n",
       "      <td>-0.660391</td>\n",
       "      <td>2.527540</td>\n",
       "      <td>-4.467528</td>\n",
       "      <td>-10.178945</td>\n",
       "      <td>-8.181026</td>\n",
       "      <td>-5.690276</td>\n",
       "      <td>-9.741242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>agricultural02.tif</td>\n",
       "      <td>-17.590063</td>\n",
       "      <td>-11.227840</td>\n",
       "      <td>-2.726588</td>\n",
       "      <td>-4.989417</td>\n",
       "      <td>-4.771765</td>\n",
       "      <td>-0.278810</td>\n",
       "      <td>-1.081569</td>\n",
       "      <td>-10.944439</td>\n",
       "      <td>-14.005670</td>\n",
       "      <td>...</td>\n",
       "      <td>-19.861160</td>\n",
       "      <td>-4.985163</td>\n",
       "      <td>-12.073009</td>\n",
       "      <td>-0.787942</td>\n",
       "      <td>2.364157</td>\n",
       "      <td>-4.569351</td>\n",
       "      <td>-10.536433</td>\n",
       "      <td>-8.334929</td>\n",
       "      <td>-5.815950</td>\n",
       "      <td>-9.914953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>agricultural03.tif</td>\n",
       "      <td>-17.511562</td>\n",
       "      <td>-11.085929</td>\n",
       "      <td>-2.736357</td>\n",
       "      <td>-4.907364</td>\n",
       "      <td>-4.601976</td>\n",
       "      <td>-0.205986</td>\n",
       "      <td>-1.070554</td>\n",
       "      <td>-10.920285</td>\n",
       "      <td>-13.756444</td>\n",
       "      <td>...</td>\n",
       "      <td>-19.591187</td>\n",
       "      <td>-4.896352</td>\n",
       "      <td>-11.999438</td>\n",
       "      <td>-0.660690</td>\n",
       "      <td>2.544987</td>\n",
       "      <td>-4.498331</td>\n",
       "      <td>-10.237048</td>\n",
       "      <td>-8.201381</td>\n",
       "      <td>-5.712914</td>\n",
       "      <td>-9.778503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>agricultural04.tif</td>\n",
       "      <td>-18.363272</td>\n",
       "      <td>-11.981666</td>\n",
       "      <td>-2.868964</td>\n",
       "      <td>-5.673901</td>\n",
       "      <td>-5.192054</td>\n",
       "      <td>-0.712970</td>\n",
       "      <td>-1.946154</td>\n",
       "      <td>-11.435550</td>\n",
       "      <td>-14.883910</td>\n",
       "      <td>...</td>\n",
       "      <td>-20.801493</td>\n",
       "      <td>-5.596359</td>\n",
       "      <td>-12.954803</td>\n",
       "      <td>-1.534384</td>\n",
       "      <td>2.228042</td>\n",
       "      <td>-5.711013</td>\n",
       "      <td>-11.136153</td>\n",
       "      <td>-8.987082</td>\n",
       "      <td>-6.150424</td>\n",
       "      <td>-10.468662</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 345 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0          0          1         2         3         4    \\\n",
       "0  agricultural00.tif -17.498186 -11.243931 -2.828087 -5.019659 -4.800480   \n",
       "1  agricultural01.tif -17.414495 -10.923462 -2.705335 -4.852305 -4.538103   \n",
       "2  agricultural02.tif -17.590063 -11.227840 -2.726588 -4.989417 -4.771765   \n",
       "3  agricultural03.tif -17.511562 -11.085929 -2.736357 -4.907364 -4.601976   \n",
       "4  agricultural04.tif -18.363272 -11.981666 -2.868964 -5.673901 -5.192054   \n",
       "\n",
       "        5         6          7          8      ...            334       335  \\\n",
       "0 -0.314717 -1.240391 -10.934299 -13.917276    ...     -19.817291 -5.006012   \n",
       "1 -0.125256 -1.075972 -10.810599 -13.663400    ...     -19.632097 -4.853601   \n",
       "2 -0.278810 -1.081569 -10.944439 -14.005670    ...     -19.861160 -4.985163   \n",
       "3 -0.205986 -1.070554 -10.920285 -13.756444    ...     -19.591187 -4.896352   \n",
       "4 -0.712970 -1.946154 -11.435550 -14.883910    ...     -20.801493 -5.596359   \n",
       "\n",
       "         336       337       338       339        340       341       342  \\\n",
       "0 -12.085507 -0.838910  2.503154 -4.625121 -10.408319 -8.315767 -5.782712   \n",
       "1 -11.882241 -0.660391  2.527540 -4.467528 -10.178945 -8.181026 -5.690276   \n",
       "2 -12.073009 -0.787942  2.364157 -4.569351 -10.536433 -8.334929 -5.815950   \n",
       "3 -11.999438 -0.660690  2.544987 -4.498331 -10.237048 -8.201381 -5.712914   \n",
       "4 -12.954803 -1.534384  2.228042 -5.711013 -11.136153 -8.987082 -6.150424   \n",
       "\n",
       "         343  \n",
       "0  -9.969353  \n",
       "1  -9.741242  \n",
       "2  -9.914953  \n",
       "3  -9.778503  \n",
       "4 -10.468662  \n",
       "\n",
       "[5 rows x 345 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result.to_csv('Features Extracted/UCMerced/Finetune/Single/UCM-VGG16-24epoch-fc1000-68-fine2.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Get the first weight of each layer to check how big by sending image through\n",
    "for name in f.attrs['layer_names']:\n",
    "    try:\n",
    "        model.get_layer(name).output\n",
    "    except:\n",
    "        continue\n",
    "    intermediate_layer_model = Model(input=model.input,\n",
    "                                     output=model.get_layer(name).output)\n",
    "    img = image.load_img(img_paths[0], target_size=(224, 224))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    test = intermediate_layer_model.predict(x)\n",
    "    print name\n",
    "    print test[0].flatten()[0]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
