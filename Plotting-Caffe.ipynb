{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use to Parse through text file for Caffe to obtain train and test loss/accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "matplotlib.use('AGG') \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_line_for_net_output(regex_obj, row, row_dict_list,\n",
    "                              line, iteration, seconds, learning_rate):\n",
    "    \"\"\"Parse a single line for training or test output\n",
    "    Returns a a tuple with (row_dict_list, row)\n",
    "    row: may be either a new row or an augmented version of the current row\n",
    "    row_dict_list: may be either the current row_dict_list or an augmented\n",
    "    version of the current row_dict_list\n",
    "    \"\"\"\n",
    "\n",
    "    output_match = regex_obj.search(line)\n",
    "    if output_match:\n",
    "        if not row or row['NumIters'] != iteration:\n",
    "            # Push the last row and start a new one\n",
    "            if row:\n",
    "                # If we're on a new iteration, push the last row\n",
    "                # This will probably only happen for the first row; otherwise\n",
    "                # the full row checking logic below will push and clear full\n",
    "                # rows\n",
    "                row_dict_list.append(row)\n",
    "\n",
    "            row = OrderedDict([\n",
    "                ('NumIters', iteration),\n",
    "                ('Seconds', seconds),\n",
    "                ('LearningRate', learning_rate)\n",
    "            ])\n",
    "\n",
    "        # output_num is not used; may be used in the future\n",
    "        # output_num = output_match.group(1)\n",
    "        output_name = output_match.group(2)\n",
    "        output_val = output_match.group(3)\n",
    "        row[output_name] = float(output_val)\n",
    "\n",
    "    if row and len(row_dict_list) >= 1 and len(row) == len(row_dict_list[0]):\n",
    "        # The row is full, based on the fact that it has the same number of\n",
    "        # columns as the first row; append it to the list\n",
    "        row_dict_list.append(row)\n",
    "        row = None\n",
    "\n",
    "    return row_dict_list, row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fix_initial_nan_learning_rate(dict_list):\n",
    "    \"\"\"Correct initial value of learning rate\n",
    "    Learning rate is normally not printed until after the initial test and\n",
    "    training step, which means the initial testing and training rows have\n",
    "    LearningRate = NaN. Fix this by copying over the LearningRate from the\n",
    "    second row, if it exists.\n",
    "    \"\"\"\n",
    "\n",
    "    if len(dict_list) > 1:\n",
    "        dict_list[0]['LearningRate'] = dict_list[1]['LearningRate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def parse_log(path_to_log):\n",
    "    \"\"\"Parse log file\n",
    "    Returns (train_dict_list, test_dict_list)\n",
    "    train_dict_list and test_dict_list are lists of dicts that define the table\n",
    "    rows\n",
    "    \"\"\"\n",
    "\n",
    "    regex_iteration = re.compile('Iteration (\\d+)')\n",
    "    regex_train_output = re.compile('Train net output #(\\d+): (\\S+) = ([\\.\\deE+-]+)')\n",
    "    regex_test_output = re.compile('Test net output #(\\d+): (\\S+) = ([\\.\\deE+-]+)')\n",
    "    regex_learning_rate = re.compile('lr = ([-+]?[0-9]*\\.?[0-9]+([eE]?[-+]?[0-9]+)?)')\n",
    "\n",
    "    # Pick out lines of interest\n",
    "    iteration = -1\n",
    "    learning_rate = float('NaN')\n",
    "    train_dict_list = []\n",
    "    test_dict_list = []\n",
    "    train_row = None\n",
    "    test_row = None\n",
    "    \n",
    "    #logfile_year = extract_seconds.get_log_created_year(path_to_log)\n",
    "    with open(path_to_log) as f:\n",
    "        #start_time = extract_seconds.get_start_time(f, logfile_year)\n",
    "\n",
    "        for line in f:\n",
    "            iteration_match = regex_iteration.search(line)\n",
    "            if iteration_match:\n",
    "                iteration = float(iteration_match.group(1))\n",
    "            if iteration == -1:\n",
    "                # Only start parsing for other stuff if we've found the first\n",
    "                # iteration\n",
    "                continue\n",
    "\n",
    "            #time = extract_seconds.extract_datetime_from_line(line, logfile_year)\n",
    "            #seconds = (time - start_time).total_seconds()\n",
    "\n",
    "            learning_rate_match = regex_learning_rate.search(line)\n",
    "            if learning_rate_match:\n",
    "                learning_rate = float(learning_rate_match.group(1))\n",
    "\n",
    "            train_dict_list, train_row = parse_line_for_net_output(\n",
    "                regex_train_output, train_row, train_dict_list,\n",
    "                line, iteration, 0, learning_rate\n",
    "            )\n",
    "            test_dict_list, test_row = parse_line_for_net_output(\n",
    "                regex_test_output, test_row, test_dict_list,\n",
    "                line, iteration, 0, learning_rate\n",
    "            )\n",
    "\n",
    "    fix_initial_nan_learning_rate(train_dict_list)\n",
    "    fix_initial_nan_learning_rate(test_dict_list)\n",
    "\n",
    "    return train_dict_list, test_dict_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_dict_list, test_dict_list = parse_log('Caffe models/ResNet50/output/1000ResNet50fixedlog.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('NumIters', 1000.0),\n",
       "             ('Seconds', 0),\n",
       "             ('LearningRate', 0.0001),\n",
       "             ('label', 188.64),\n",
       "             ('probt', 0.00327022)])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dict_list[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_loss = []\n",
    "iterstr = []\n",
    "for t in train_dict_list:\n",
    "    train_loss.append(t['prob'])\n",
    "    iterstr.append(t['NumIters'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_acc = []\n",
    "train_loss = []\n",
    "iters = []\n",
    "for t,d in zip(train_dict_list,test_dict_list):\n",
    "    train_loss.append(t['loss'])\n",
    "    test_acc.append(d['accuracy'])\n",
    "    iters.append(t['NumIters'])\n",
    "test_acc = np.array(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Plot\n",
    "fig, ax1 = plt.subplots()\n",
    "t = np.arange(0.01, 10.0, 0.01)\n",
    "ax1.plot(iters, 100*test_acc, 'b-')\n",
    "ax1.set_xlabel('Number of Iterations')\n",
    "# Make the y-axis label and tick labels match the line color.\n",
    "ax1.set_ylabel('Validaiton Accuracy', color='b')\n",
    "for tl in ax1.get_yticklabels():\n",
    "    tl.set_color('b')\n",
    "\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(iterstr, train_loss, 'r-')\n",
    "ax2.set_ylabel('Training Loss', color='r')\n",
    "for tl in ax2.get_yticklabels():\n",
    "    tl.set_color('r')\n",
    "plt.show()\n",
    "#fig.savefig('Caffe models/ResNet50/10000iter.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
